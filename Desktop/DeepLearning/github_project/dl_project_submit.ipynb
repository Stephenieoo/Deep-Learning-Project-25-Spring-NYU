{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blluWnA1jpWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde3f4c3-f12d-418c-b40b-e17ebf5469d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch: 0 | Progress: [351/391] | Batch Loss: 1.4270\n",
            "Epoch: 0 | Train Loss: 1.5763 | Test Loss: 1.6025 | Test Acc: 50.32%\n",
            "Epoch: 1 | Progress: [351/391] | Batch Loss: 1.0468\n",
            "Epoch: 2 | Progress: [351/391] | Batch Loss: 0.9700\n",
            "Epoch: 3 | Progress: [351/391] | Batch Loss: 0.8007\n",
            "Epoch: 4 | Progress: [351/391] | Batch Loss: 0.7561\n",
            "Epoch: 5 | Progress: [351/391] | Batch Loss: 0.8172\n",
            "Epoch: 5 | Train Loss: 0.6841 | Test Loss: 0.7057 | Test Acc: 77.47%\n",
            "Epoch: 6 | Progress: [351/391] | Batch Loss: 0.6822\n",
            "Epoch: 7 | Progress: [351/391] | Batch Loss: 0.6114\n",
            "Epoch: 8 | Progress: [351/391] | Batch Loss: 0.5487\n",
            "Epoch: 9 | Progress: [351/391] | Batch Loss: 0.3403\n",
            "Epoch: 9 | Train Loss: 0.5354 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 9 | Latest Train Loss: 0.5354 | Latest Test Acc: 77.47%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 10 | Progress: [351/391] | Batch Loss: 0.5028\n",
            "Epoch: 10 | Train Loss: 0.5082 | Test Loss: 0.5476 | Test Acc: 82.12%\n",
            "Epoch: 11 | Progress: [351/391] | Batch Loss: 0.5606\n",
            "Epoch: 12 | Progress: [351/391] | Batch Loss: 0.5069\n",
            "Epoch: 13 | Progress: [351/391] | Batch Loss: 0.6034\n",
            "Epoch: 14 | Progress: [351/391] | Batch Loss: 0.4568\n",
            "Epoch: 15 | Progress: [351/391] | Batch Loss: 0.3736\n",
            "Epoch: 15 | Train Loss: 0.4168 | Test Loss: 0.4511 | Test Acc: 85.53%\n",
            "Epoch: 16 | Progress: [351/391] | Batch Loss: 0.5365\n",
            "Epoch: 17 | Progress: [351/391] | Batch Loss: 0.3746\n",
            "Epoch: 18 | Progress: [351/391] | Batch Loss: 0.5034\n",
            "Epoch: 19 | Progress: [351/391] | Batch Loss: 0.4372\n",
            "Epoch: 19 | Train Loss: 0.3661 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 19 | Latest Train Loss: 0.3661 | Latest Test Acc: 85.53%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 20 | Progress: [351/391] | Batch Loss: 0.4330\n",
            "Epoch: 20 | Train Loss: 0.3578 | Test Loss: 0.4356 | Test Acc: 86.11%\n",
            "Epoch: 21 | Progress: [351/391] | Batch Loss: 0.4023\n",
            "Epoch: 22 | Progress: [351/391] | Batch Loss: 0.3814\n",
            "Epoch: 23 | Progress: [351/391] | Batch Loss: 0.3144\n",
            "Epoch: 24 | Progress: [351/391] | Batch Loss: 0.3798\n",
            "Epoch: 25 | Progress: [351/391] | Batch Loss: 0.2737\n",
            "Epoch: 25 | Train Loss: 0.3168 | Test Loss: 0.4456 | Test Acc: 86.27%\n",
            "Epoch: 26 | Progress: [351/391] | Batch Loss: 0.3996\n",
            "Epoch: 27 | Progress: [351/391] | Batch Loss: 0.2262\n",
            "Epoch: 28 | Progress: [351/391] | Batch Loss: 0.3325\n",
            "Epoch: 29 | Progress: [351/391] | Batch Loss: 0.2809\n",
            "Epoch: 29 | Train Loss: 0.2761 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 29 | Latest Train Loss: 0.2761 | Latest Test Acc: 86.27%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 30 | Progress: [351/391] | Batch Loss: 0.3253\n",
            "Epoch: 30 | Train Loss: 0.2716 | Test Loss: 0.3067 | Test Acc: 90.24%\n",
            "Epoch: 31 | Progress: [351/391] | Batch Loss: 0.2796\n",
            "Epoch: 32 | Progress: [351/391] | Batch Loss: 0.1889\n",
            "Epoch: 33 | Progress: [351/391] | Batch Loss: 0.2004\n",
            "Epoch: 34 | Progress: [351/391] | Batch Loss: 0.2448\n",
            "Epoch: 35 | Progress: [351/391] | Batch Loss: 0.1843\n",
            "Epoch: 35 | Train Loss: 0.2391 | Test Loss: 0.3462 | Test Acc: 89.03%\n",
            "Epoch: 36 | Progress: [351/391] | Batch Loss: 0.1555\n",
            "Epoch: 37 | Progress: [351/391] | Batch Loss: 0.3180\n",
            "Epoch: 38 | Progress: [351/391] | Batch Loss: 0.1558\n",
            "Epoch: 39 | Progress: [351/391] | Batch Loss: 0.1883\n",
            "Epoch: 39 | Train Loss: 0.2162 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 39 | Latest Train Loss: 0.2162 | Latest Test Acc: 89.03%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 40 | Progress: [351/391] | Batch Loss: 0.1619\n",
            "Epoch: 40 | Train Loss: 0.2127 | Test Loss: 0.2828 | Test Acc: 90.70%\n",
            "Epoch: 41 | Progress: [351/391] | Batch Loss: 0.1902\n",
            "Epoch: 42 | Progress: [351/391] | Batch Loss: 0.2179\n",
            "Epoch: 43 | Progress: [351/391] | Batch Loss: 0.1702\n",
            "Epoch: 44 | Progress: [351/391] | Batch Loss: 0.2442\n",
            "Epoch: 45 | Progress: [351/391] | Batch Loss: 0.1878\n",
            "Epoch: 45 | Train Loss: 0.1848 | Test Loss: 0.2742 | Test Acc: 91.06%\n",
            "Epoch: 46 | Progress: [351/391] | Batch Loss: 0.2003\n",
            "Epoch: 47 | Progress: [351/391] | Batch Loss: 0.1877\n",
            "Epoch: 48 | Progress: [351/391] | Batch Loss: 0.1438\n",
            "Epoch: 49 | Progress: [351/391] | Batch Loss: 0.1577\n",
            "Epoch: 49 | Train Loss: 0.1657 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 49 | Latest Train Loss: 0.1657 | Latest Test Acc: 91.06%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 50 | Progress: [351/391] | Batch Loss: 0.1994\n",
            "Epoch: 50 | Train Loss: 0.1641 | Test Loss: 0.2734 | Test Acc: 91.30%\n",
            "Epoch: 51 | Progress: [351/391] | Batch Loss: 0.2196\n",
            "Epoch: 52 | Progress: [351/391] | Batch Loss: 0.1355\n",
            "Epoch: 53 | Progress: [351/391] | Batch Loss: 0.1187\n",
            "Epoch: 54 | Progress: [351/391] | Batch Loss: 0.1154\n",
            "Epoch: 55 | Progress: [351/391] | Batch Loss: 0.0999\n",
            "Epoch: 55 | Train Loss: 0.1336 | Test Loss: 0.2738 | Test Acc: 91.96%\n",
            "Epoch: 56 | Progress: [351/391] | Batch Loss: 0.1718\n",
            "Epoch: 57 | Progress: [351/391] | Batch Loss: 0.1677\n",
            "Epoch: 58 | Progress: [351/391] | Batch Loss: 0.1299\n",
            "Epoch: 59 | Progress: [351/391] | Batch Loss: 0.1668\n",
            "Epoch: 59 | Train Loss: 0.1181 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 59 | Latest Train Loss: 0.1181 | Latest Test Acc: 91.96%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 60 | Progress: [351/391] | Batch Loss: 0.1830\n",
            "Epoch: 60 | Train Loss: 0.1144 | Test Loss: 0.2462 | Test Acc: 92.47%\n",
            "Epoch: 61 | Progress: [351/391] | Batch Loss: 0.1922\n",
            "Epoch: 62 | Progress: [351/391] | Batch Loss: 0.1452\n",
            "Epoch: 63 | Progress: [351/391] | Batch Loss: 0.1014\n",
            "Epoch: 64 | Progress: [351/391] | Batch Loss: 0.0750\n",
            "Epoch: 65 | Progress: [351/391] | Batch Loss: 0.0704\n",
            "Epoch: 65 | Train Loss: 0.0937 | Test Loss: 0.2397 | Test Acc: 92.69%\n",
            "Epoch: 66 | Progress: [351/391] | Batch Loss: 0.1023\n",
            "Epoch: 67 | Progress: [351/391] | Batch Loss: 0.0685\n",
            "Epoch: 68 | Progress: [351/391] | Batch Loss: 0.1002\n",
            "Epoch: 69 | Progress: [351/391] | Batch Loss: 0.1004\n",
            "Epoch: 69 | Train Loss: 0.0838 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 69 | Latest Train Loss: 0.0838 | Latest Test Acc: 92.69%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 70 | Progress: [351/391] | Batch Loss: 0.0634\n",
            "Epoch: 70 | Train Loss: 0.0796 | Test Loss: 0.2288 | Test Acc: 93.27%\n",
            "Epoch: 71 | Progress: [351/391] | Batch Loss: 0.0564\n",
            "Epoch: 72 | Progress: [351/391] | Batch Loss: 0.0457\n",
            "Epoch: 73 | Progress: [351/391] | Batch Loss: 0.0342\n",
            "Epoch: 74 | Progress: [351/391] | Batch Loss: 0.0906\n",
            "Epoch: 75 | Progress: [351/391] | Batch Loss: 0.0734\n",
            "Epoch: 75 | Train Loss: 0.0657 | Test Loss: 0.2198 | Test Acc: 93.43%\n",
            "Epoch: 76 | Progress: [351/391] | Batch Loss: 0.0510\n",
            "Epoch: 77 | Progress: [351/391] | Batch Loss: 0.0822\n",
            "Epoch: 78 | Progress: [351/391] | Batch Loss: 0.0741\n",
            "Epoch: 79 | Progress: [351/391] | Batch Loss: 0.0572\n",
            "Epoch: 79 | Train Loss: 0.0566 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 79 | Latest Train Loss: 0.0566 | Latest Test Acc: 93.43%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 80 | Progress: [351/391] | Batch Loss: 0.0335\n",
            "Epoch: 80 | Train Loss: 0.0565 | Test Loss: 0.2115 | Test Acc: 93.74%\n",
            "Epoch: 81 | Progress: [351/391] | Batch Loss: 0.0439\n",
            "Epoch: 82 | Progress: [351/391] | Batch Loss: 0.0441\n",
            "Epoch: 83 | Progress: [351/391] | Batch Loss: 0.0631\n",
            "Epoch: 84 | Progress: [351/391] | Batch Loss: 0.0541\n",
            "Epoch: 85 | Progress: [351/391] | Batch Loss: 0.0300\n",
            "Epoch: 85 | Train Loss: 0.0490 | Test Loss: 0.2115 | Test Acc: 93.92%\n",
            "Epoch: 86 | Progress: [351/391] | Batch Loss: 0.0263\n",
            "Epoch: 87 | Progress: [351/391] | Batch Loss: 0.0600\n",
            "Epoch: 88 | Progress: [351/391] | Batch Loss: 0.0255\n",
            "Epoch: 89 | Progress: [351/391] | Batch Loss: 0.0495\n",
            "Epoch: 89 | Train Loss: 0.0439 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 89 | Latest Train Loss: 0.0439 | Latest Test Acc: 93.92%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 90 | Progress: [351/391] | Batch Loss: 0.0535\n",
            "Epoch: 90 | Train Loss: 0.0455 | Test Loss: 0.2086 | Test Acc: 93.81%\n",
            "Epoch: 91 | Progress: [351/391] | Batch Loss: 0.0224\n",
            "Epoch: 92 | Progress: [351/391] | Batch Loss: 0.0659\n",
            "Epoch: 93 | Progress: [351/391] | Batch Loss: 0.0219\n",
            "Epoch: 94 | Progress: [351/391] | Batch Loss: 0.0228\n",
            "Epoch: 95 | Progress: [351/391] | Batch Loss: 0.0291\n",
            "Epoch: 95 | Train Loss: 0.0431 | Test Loss: 0.2072 | Test Acc: 93.93%\n",
            "Epoch: 96 | Progress: [351/391] | Batch Loss: 0.0323\n",
            "Epoch: 97 | Progress: [351/391] | Batch Loss: 0.0450\n",
            "Epoch: 98 | Progress: [351/391] | Batch Loss: 0.0559\n",
            "Epoch: 99 | Progress: [351/391] | Batch Loss: 0.0307\n",
            "Epoch: 99 | Train Loss: 0.0419 | --------------------------------------------------------------------------------\n",
            "[阶段总结] Epoch: 99 | Latest Train Loss: 0.0419 | Latest Test Acc: 93.93%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Defining residual blocks\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Defining Lightweight ResNet\n",
        "class LightResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LightResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        # Initial Convolutional Layer\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # sequence of residual blocks\n",
        "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
        "\n",
        "        # Global average pooling and full connectivity\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def _make_layer(self, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Print model parameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LightResNet().to(device)\n",
        "\n",
        "# Data enhancement and loading\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # data enhancement\n",
        "    transforms.RandomCrop(32, padding=4),  # Output size 32 x 32\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),  # Color Jitter\n",
        "    transforms.RandomRotation(15),  # random rotation\n",
        "    transforms.ToTensor(), # Convert to Tensor + auto-normalize to [0,1]\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),  # normalized mean\n",
        "                         (0.2023, 0.1994, 0.2010)), # normalized standard deviation\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3))  # Cutout\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to Tensor + auto-normalize to [0,1]\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),   # standardization\n",
        "                         (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
        "\n",
        "# Training configuration\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Logger\n",
        "train_losses = []  # Record the training loss for each epoch\n",
        "test_accuracies = []  # Record test accuracy for each epoch\n",
        "\n",
        "# Modified training function (training loss print added)\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print batch training progress in real time\n",
        "        if batch_idx % 50 == 0:  # Prints every 50 batch\n",
        "            current_loss = loss.item()\n",
        "            current_batch = batch_idx + 1\n",
        "            total_batches = len(trainloader)\n",
        "            print(f'\\rEpoch: {epoch} | '\n",
        "                  f'Progress: [{current_batch}/{total_batches}] | '\n",
        "                  f'Batch Loss: {current_loss:.4f}', end='', flush=True)\n",
        "\n",
        "    # Print the average training loss at the end of each epoch\n",
        "    avg_loss = total_loss / len(trainloader)\n",
        "    train_losses.append(avg_loss)  # Recording training losses\n",
        "    print(f'\\nEpoch: {epoch} | '\n",
        "          f'Train Loss: {avg_loss:.4f} | ', end='')\n",
        "\n",
        "# test function (add accuracy print)\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    avg_test_loss = test_loss / len(testloader)\n",
        "    test_accuracies.append(acc)  # Record test accuracy\n",
        "    print(f'Test Loss: {avg_test_loss:.4f} | '\n",
        "          f'Test Acc: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Modified training loop (add progress bar style output)\n",
        "for epoch in range(100):\n",
        "    # training phase\n",
        "    train(epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "    # Tested every 5 epochs\n",
        "    if epoch % 5 == 0 or epoch == 199:  # Final epoch forced test\n",
        "        test_acc = test()\n",
        "\n",
        "    # Stage Summary Print\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('-'*80)\n",
        "        print(f'[Phase Summary] Epoch: {epoch} | '\n",
        "              f'Latest Train Loss: {train_losses[-1]:.4f} | '\n",
        "              f'Latest Test Acc: {test_accuracies[-1]:.2f}%')\n",
        "        print('-'*80)\n",
        "\n",
        "# save the model\n",
        "torch.save(model.state_dict(), 'cifar10_resnet.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class ResidualBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(out_channels)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = torch.nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                torch.nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class LightResNet(torch.nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LightResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
        "\n",
        "        self.avg_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = torch.nn.Linear(256, num_classes)\n",
        "\n",
        "    def _make_layer(self, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "\n",
        "def load_test_data():\n",
        "    test_data_dict = unpickle(\"cifar_test_nolabel.pkl\")\n",
        "    images = test_data_dict[b'data']\n",
        "\n",
        "    # Conversion to numpy arrays in HWC format (not Tensor!)\n",
        "    images = images.reshape(-1, 32, 32, 3).astype(np.uint8)  # Shape (N,32,32,3), value range 0-255\n",
        "    # Define test preprocessing (includes ToTensor and Normalize)\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),  # Automatically convert numpy to Tensor + normalize to [0,1]\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    # Apply preprocessing (be a numpy array)\n",
        "    transformed_images = []\n",
        "    for img in images:\n",
        "        transformed_img = transform_test(img)\n",
        "        transformed_images.append(transformed_img)\n",
        "\n",
        "    return torch.stack(transformed_images)   # Merge all the images and the output shape should be (N, 3, 32, 32)\n",
        "\n",
        "\n",
        "test_images = load_test_data()\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(test_images)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "for batch in test_loader:\n",
        "    images = batch[0]\n",
        "    print(\"Batch images shape:\", images.shape)\n",
        "    break\n",
        "\n",
        "# Loading Models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LightResNet(num_classes=10).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"cifar10_resnet.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# inference\n",
        "y_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        images = batch[0].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Generating Submission Files\n",
        "submission_df = pd.DataFrame({'ID': np.arange(len(y_preds)), 'Labels': y_preds})\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ CSV file generated: submission.csv\")\n"
      ],
      "metadata": {
        "id": "YUdoI_3xj7xe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bbe7b2d-b50c-4834-e307-edbe4bbb249d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Test images shape: torch.Size([10000, 3, 32, 32])\n",
            "Batch images shape: torch.Size([100, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2eba86d19389>:130: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"cifar10_resnet.pth\", map_location=device))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for LightResNet:\n\tUnexpected key(s) in state_dict: \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer1.2.se.fc.0.weight\", \"layer1.2.se.fc.0.bias\", \"layer1.2.se.fc.2.weight\", \"layer1.2.se.fc.2.bias\", \"layer1.0.se.fc.0.weight\", \"layer1.0.se.fc.0.bias\", \"layer1.0.se.fc.2.weight\", \"layer1.0.se.fc.2.bias\", \"layer1.1.se.fc.0.weight\", \"layer1.1.se.fc.0.bias\", \"layer1.1.se.fc.2.weight\", \"layer1.1.se.fc.2.bias\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.2.se.fc.0.weight\", \"layer2.2.se.fc.0.bias\", \"layer2.2.se.fc.2.weight\", \"layer2.2.se.fc.2.bias\", \"layer2.0.se.fc.0.weight\", \"layer2.0.se.fc.0.bias\", \"layer2.0.se.fc.2.weight\", \"layer2.0.se.fc.2.bias\", \"layer2.1.se.fc.0.weight\", \"layer2.1.se.fc.0.bias\", \"layer2.1.se.fc.2.weight\", \"layer2.1.se.fc.2.bias\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.2.se.fc.0.weight\", \"layer3.2.se.fc.0.bias\", \"layer3.2.se.fc.2.weight\", \"layer3.2.se.fc.2.bias\", \"layer3.0.se.fc.0.weight\", \"layer3.0.se.fc.0.bias\", \"layer3.0.se.fc.2.weight\", \"layer3.0.se.fc.2.bias\", \"layer3.1.se.fc.0.weight\", \"layer3.1.se.fc.0.bias\", \"layer3.1.se.fc.2.weight\", \"layer3.1.se.fc.2.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2eba86d19389>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cifar10_resnet.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LightResNet:\n\tUnexpected key(s) in state_dict: \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer1.2.se.fc.0.weight\", \"layer1.2.se.fc.0.bias\", \"layer1.2.se.fc.2.weight\", \"layer1.2.se.fc.2.bias\", \"layer1.0.se.fc.0.weight\", \"layer1.0.se.fc.0.bias\", \"layer1.0.se.fc.2.weight\", \"layer1.0.se.fc.2.bias\", \"layer1.1.se.fc.0.weight\", \"layer1.1.se.fc.0.bias\", \"layer1.1.se.fc.2.weight\", \"layer1.1.se.fc.2.bias\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.2.se.fc.0.weight\", \"layer2.2.se.fc.0.bias\", \"layer2.2.se.fc.2.weight\", \"layer2.2.se.fc.2.bias\", \"layer2.0.se.fc.0.weight\", \"layer2.0.se.fc.0.bias\", \"layer2.0.se.fc.2.weight\", \"layer2.0.se.fc.2.bias\", \"layer2.1.se.fc.0.weight\", \"layer2.1.se.fc.0.bias\", \"layer2.1.se.fc.2.weight\", \"layer2.1.se.fc.2.bias\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"lay..."
          ]
        }
      ]
    }
  ]
}